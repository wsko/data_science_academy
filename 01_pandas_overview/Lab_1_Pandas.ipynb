{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2920ca30",
   "metadata": {
    "id": "2920ca30"
   },
   "source": [
    "## Lab 1. Pandas\n",
    "\n",
    "### Structured Data Manipulation and Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd74a0",
   "metadata": {
    "id": "e1bd74a0"
   },
   "source": [
    "## Part 1. Data Transformation and Group By Analysis\n",
    "\n",
    "__Data__: Toronto Parking Tickets dataset `Parking_Tickets_Toronto2020.csv` (original data source https://www.toronto.ca/city-government/data-research-maps/open-data/) describes parking infractions in the City of Toronto issued between April and August 2020.  \n",
    "\n",
    "Data dictionary:\n",
    "\n",
    "- date_of_infraction (int) the date of parking violation as YYYYMMDD\n",
    "- infraction (str) description of the parking violation\n",
    "- fine (int) parkng ticket amount\n",
    "- address (str) nearest house number and street to the location where the ticket was issued\n",
    "- province (str) province or state of origin of the car's license plate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ace2021",
   "metadata": {
    "id": "5ace2021"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b8443",
   "metadata": {
    "id": "fb3b8443"
   },
   "source": [
    "#### 1.1- Data Import and Inspection\n",
    "\n",
    "1. Import CSV data into a pandas data frame\n",
    "2. Inspect the data frame:\n",
    "    - how many rows and columns are there?\n",
    "    - what data types are there?\n",
    "    - describe the numerical and object columns\n",
    "    - what is the number of unique values in each column?\n",
    "3. Print the fist 5 rows of the columns containing character strings ('object' data type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5ca41",
   "metadata": {
    "id": "83a5ca41"
   },
   "source": [
    "#### 1.2- Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc55fb8a",
   "metadata": {
    "id": "bc55fb8a"
   },
   "source": [
    "1. Convert the column \"date_of_infraction\" into the date-time format\n",
    "    - use the `apply` method and `strptime` function from the `datetime` package to create a new column `\"date\"` containing the dates of infractions expressed as a date-time object\n",
    "    - drop the original `\"date_of_infraction\"` column from the data frame\n",
    "    - create two new columns \"month\" and \"week_day\" containing the Month and Day of the week extracted from the \"date\" column. Hint: use the \"apply\" method and strftime function. Resource:  https://strftime.org/\n",
    "2. Create a new column `\"street\"` by extracting street name from the \"address\" column\n",
    "    - Hint: the addresses always begin with a house bumber followed by a space folowed by the street name\n",
    "    - List the top 10 most frequent street names\n",
    "    - How many unique combinations of address and street are there?\n",
    "3. Convert the `\"week_day\"` and `\"month\"` columns into the Categorical data type\n",
    "    - also make sure that your categories are properly ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e06c03",
   "metadata": {
    "id": "65e06c03"
   },
   "source": [
    "#### 1.3- Subsetting and GroupBy Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06384c0",
   "metadata": {
    "id": "e06384c0"
   },
   "source": [
    "1. Find the top 5 most frequent infraction categories and top 10 most frequently occurring streets\n",
    "2. Build a subset of the original data frame where the infractions and streets are those you identified in step 1\n",
    "    - How many rows does the subset data frame contain?\n",
    "2. Using the subset data from step 2 and the groupby method, compute:\n",
    "    - mean fines for each month\n",
    "    - mean fines for each week day\n",
    "    - find the provinces which paid a total of > 10000 in parking tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527223ca",
   "metadata": {
    "id": "527223ca"
   },
   "source": [
    "## Part 2.  Merging. Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aab6f3",
   "metadata": {
    "id": "16aab6f3"
   },
   "source": [
    "#### Data:\n",
    "\n",
    "- `debt_public.csv`\n",
    "    - this data table contains the following columns:\n",
    "        - Country\n",
    "        - gross_debt_per_GDP (gross government debt as percent of GDP)\n",
    "        - net_debt_per_GDP (net government debt as percent of GDP)\n",
    "\n",
    "\n",
    "- `gdp_by_country.csv`\n",
    "    - gross domestic product estimates from three independent sources (IMF, WB, CIA) and the year of the estimate\n",
    "\n",
    "\n",
    "- `continents.csv`\n",
    "    - a table of countries and continents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a5d6a",
   "metadata": {
    "id": "441a5d6a"
   },
   "source": [
    "#### 2.1- Import and Inspect Data\n",
    "\n",
    "1. Import data from the following sources: `debt_public.csv`, `gdp_by_country.csv`, `continents.csv` into Pandas data frames\n",
    "2. Inspect the data frames:\n",
    "    - Preview a few sample rows\n",
    "    - Preview and inspect descriptive statistics for the numerical and string columns\n",
    "3. Does any of the three data frames contain missing data (`NaN`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89288c9",
   "metadata": {
    "id": "f89288c9"
   },
   "source": [
    "#### 2.2- Data Transformation\n",
    "\n",
    "1. gdp data:\n",
    "    - remove all except 'Country' and 'CIA_Estimate'\n",
    "    - rename 'CIA_Estimate' column to 'GDP'\n",
    "    - add a `\"Continent\"` column by merging the `gdp` and `continents` data frames on the `\"Country\"` column\n",
    "\n",
    "\n",
    "2. public debt data:\n",
    "    - remove rows where `\"gross_debt_per_GDP\"` is missing (`NaN`)\n",
    "    - check for the number of missing values in each column\n",
    "    - merge the `pDebt` and `gdp` data frames into a master data frame `df_debt`\n",
    "    - add a caclulated column `\"gross_pub_debt\"` for the absolute values of gross public debt using the GDP values and the values of gross debt expressed as percentage of GDP\n",
    "    - add another calculated column `\"debt_bin\"` by binning \"gross_pub_debt\" into two bins: \"Low\" and \"High\" separated by the median value of `\"gross_pub_debt\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb85f6",
   "metadata": {},
   "source": [
    "#### 2.3- impute missing values\n",
    "- verify again which columns have missing values in the master data frame `df_debt`\n",
    "- does the number of missing values justify using .dropna() (removing entire rows containing missing values)?\n",
    "- check which fillna method should be used. One possibility is to fill the NaNs with the mean of the non-missing values - this can work if the distribution is reasonably symmetrical, i.e., mean and median are close to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7240a388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
